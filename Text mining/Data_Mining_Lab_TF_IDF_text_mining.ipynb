{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLrPIe24qNyE",
        "outputId": "c6887fbb-0944-47f8-93d9-a7843b85d82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# punkt → tokenizer (to split text into words).\n",
        "\n",
        "# wordnet → for lemmatization (getting base form of words).\n",
        "\n",
        "# stopwords → list of common words like the, is, and that you will remove.\n",
        "\n",
        "# punkt_tab is a newer extra resource for tokenization."
      ],
      "metadata": {
        "id": "VDomrx3tIR2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGyYAC3Bsnam",
        "outputId": "115d7af1-d736-4809-f3f1-bf350ce575fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Load the Dataset"
      ],
      "metadata": {
        "id": "E94E2nQg4hxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from ast import literal_eval   # safer than eval\n",
        "\n",
        "# ML & evaluation\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Text preprocessing / feature extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n"
      ],
      "metadata": {
        "id": "iZt9wXU2spzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Cleaning & Convert genres → Primary Genre"
      ],
      "metadata": {
        "id": "nP_jISI44jxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your CSV\n",
        "df = pd.read_csv(\"book_details.csv\")\n",
        "\n",
        "# Drop rows with any NaNs (title/description/genres)\n",
        "df = df.dropna(subset=[\"description\", \"genres\"]).reset_index(drop=True)\n",
        "\n",
        "# Convert \"['Classics','Fiction',...]\" → ['Classics','Fiction',...]\n",
        "def parse_genres(g):\n",
        "    try:\n",
        "        return literal_eval(g)\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "df[\"genres_parsed\"] = df[\"genres\"].apply(parse_genres)\n",
        "\n",
        "# Take ONLY the first genre as the \"primary\" genre\n",
        "primary_genres = []\n",
        "indices_to_drop = []\n",
        "\n",
        "for idx, g_list in enumerate(df[\"genres_parsed\"]):\n",
        "    if len(g_list) > 0:\n",
        "        primary_genres.append(g_list[0])\n",
        "    else:\n",
        "        indices_to_drop.append(idx)\n",
        "\n",
        "# Drop rows with empty genre lists (if any)\n",
        "df = df.drop(index=indices_to_drop).reset_index(drop=True)\n",
        "\n",
        "# Add the single-label column\n",
        "df[\"primary_genre\"] = primary_genres\n",
        "\n",
        "print(df[[\"description\", \"genres\", \"primary_genre\"]].head())\n",
        "print(\"Unique primary genres:\", df[\"primary_genre\"].nunique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufisg5BKsu7C",
        "outputId": "dae72601-fe31-47ce-fcfb-f4ea6c0b0fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         description  \\\n",
            "0  The unforgettable novel of a childhood in a sl...   \n",
            "1  Harry Potter thinks he is an ordinary boy - un...   \n",
            "2  Alternate cover edition of ISBN 9780679783268S...   \n",
            "3  Discovered in the attic in which she spent the...   \n",
            "4  Librarian's note: There is an Alternate Cover ...   \n",
            "\n",
            "                                              genres primary_genre  \n",
            "0  ['Classics', 'Fiction', 'Historical Fiction', ...      Classics  \n",
            "1  ['Fantasy', 'Fiction', 'Young Adult', 'Magic',...       Fantasy  \n",
            "2  ['Classics', 'Fiction', 'Romance', 'Historical...      Classics  \n",
            "3  ['Classics', 'Nonfiction', 'History', 'Biograp...      Classics  \n",
            "4  ['Classics', 'Fiction', 'Dystopia', 'Fantasy',...      Classics  \n",
            "Unique primary genres: 151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Binary Target (Fiction vs Not Fiction)"
      ],
      "metadata": {
        "id": "HXNS-ePM4wJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_GENRE = \"Fiction\"   # << change here if you want another genre\n",
        "\n",
        "df[\"label\"] = df[\"primary_genre\"].apply(lambda g: 1 if g == TARGET_GENRE else 0)\n",
        "\n",
        "print(df[\"label\"].value_counts())\n",
        "print(df[[\"primary_genre\", \"label\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLN_YTQnsyWk",
        "outputId": "044af43b-2be3-4e1d-8ef5-f53b313293ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    4811\n",
            "1    1308\n",
            "Name: count, dtype: int64\n",
            "  primary_genre  label\n",
            "0      Classics      0\n",
            "1       Fantasy      0\n",
            "2      Classics      0\n",
            "3      Classics      0\n",
            "4      Classics      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RzklWpvtRdV",
        "outputId": "4f45048d-a21a-4e33-b7f6-8e4b435d4698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessing with NLTK\n",
        "\n",
        "We’ll create a clean text column with:\n",
        "\n",
        "lowercasing\n",
        "\n",
        "remove URLs, numbers, punctuation\n",
        "\n",
        "stopword removal\n",
        "\n",
        "lemmatization"
      ],
      "metadata": {
        "id": "OEo8Odw243EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemm = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
        "    # keep only letters and spaces\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stopwords and lemmatize\n",
        "    tokens = [lemm.lemmatize(tok) for tok in tokens if tok not in stop_words and len(tok) > 2]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"clean_description\"] = df[\"description\"].apply(clean_text)\n",
        "\n",
        "print(df[[\"description\", \"clean_description\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0BimxiHs28-",
        "outputId": "bea1208d-263c-4b23-fb4f-d3300bc0db49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         description  \\\n",
            "0  The unforgettable novel of a childhood in a sl...   \n",
            "1  Harry Potter thinks he is an ordinary boy - un...   \n",
            "2  Alternate cover edition of ISBN 9780679783268S...   \n",
            "3  Discovered in the attic in which she spent the...   \n",
            "4  Librarian's note: There is an Alternate Cover ...   \n",
            "\n",
            "                                   clean_description  \n",
            "0  unforgettable novel childhood sleepy southern ...  \n",
            "1  harry potter think ordinary boy rescued owl ta...  \n",
            "2  alternate cover edition isbn since immediate s...  \n",
            "3  discovered attic spent last year life anne fra...  \n",
            "4  librarian note alternate cover edition edition...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train–Test Split"
      ],
      "metadata": {
        "id": "ywe9Fnky46Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"clean_description\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A30miTgtEOu",
        "outputId": "fa5b6996-ff33-4d16-ded7-1785cef32df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 4895\n",
            "Test size: 1224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Models with TF-IDF (No Scaling Needed)\n",
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "UPuKNfg35AaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "nb_pipeline.fit(X_train, y_train)\n",
        "y_pred_nb = nb_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(classification_report(y_test, y_pred_nb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDMTLKrtbmn",
        "outputId": "cd0bb218-b15e-4eb1-e013-f43c7c1cfd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.7843137254901961\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      1.00      0.88       962\n",
            "           1       0.33      0.01      0.01       262\n",
            "\n",
            "    accuracy                           0.78      1224\n",
            "   macro avg       0.56      0.50      0.45      1224\n",
            "weighted avg       0.69      0.78      0.69      1224\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "o8Qhc8eL5H05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "y_pred_lr = lr_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ANCyLqSteZM",
        "outputId": "13793035-8e24-4480-f1ed-09e2c0087ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8120915032679739\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.99      0.89       962\n",
            "           1       0.82      0.16      0.26       262\n",
            "\n",
            "    accuracy                           0.81      1224\n",
            "   macro avg       0.82      0.57      0.58      1224\n",
            "weighted avg       0.81      0.81      0.76      1224\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear SVM"
      ],
      "metadata": {
        "id": "_QBmuk1N5aSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
        "    (\"clf\", LinearSVC())\n",
        "])\n",
        "\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "y_pred_svm = svm_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Linear SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18-7gsBXtl00",
        "outputId": "97ea6221-be70-4426-b5bb-87cf34bfd1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVM Accuracy: 0.8055555555555556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88       962\n",
            "           1       0.57      0.40      0.47       262\n",
            "\n",
            "    accuracy                           0.81      1224\n",
            "   macro avg       0.71      0.66      0.67      1224\n",
            "weighted avg       0.79      0.81      0.79      1224\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-Validation (e.g., Logistic Regression)\n",
        "\n",
        "We’ll do k-fold cross-validation on the training data."
      ],
      "metadata": {
        "id": "A4ZeqqnD5iv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    lr_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=kf,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"CV accuracies:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iWVoQortsZr",
        "outputId": "3662b96e-04a0-4aee-cb78-bfad3b36aa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV accuracies: [0.80183861 0.79570991 0.79673136 0.79877426 0.79570991]\n",
            "Mean CV accuracy: 0.7977528089887641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning with GridSearchCV\n",
        "## 1 Hyperparameter Tuning for Logistic Regression\n",
        "\n",
        "We tune:\n",
        "\n",
        "C (regularization strength)\n",
        "\n",
        "ngram_range\n",
        "\n",
        "max_features"
      ],
      "metadata": {
        "id": "7P4sRYrK5pRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "param_grid_lr = {\n",
        "    \"tfidf__max_features\": [3000, 5000, 8000],\n",
        "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
        "    \"clf__C\": [0.1, 1, 5],\n",
        "    \"clf__penalty\": [\"l2\"],\n",
        "    \"clf__solver\": [\"lbfgs\"]\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(\n",
        "    lr_pipeline,\n",
        "    param_grid=param_grid_lr,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best LR params:\", grid_lr.best_params_)\n",
        "print(\"Best LR CV score:\", grid_lr.best_score_)\n",
        "\n",
        "best_lr_model = grid_lr.best_estimator_\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_lr_best = best_lr_model.predict(X_test)\n",
        "print(\"Tuned LR Test Accuracy:\", accuracy_score(y_test, y_pred_lr_best))\n",
        "print(classification_report(y_test, y_pred_lr_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyZ9fQZztzAQ",
        "outputId": "ceb33576-9794-404c-9c14-83d4123e1132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "Best LR params: {'clf__C': 5, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1)}\n",
            "Best LR CV score: 0.819203268641471\n",
            "Tuned LR Test Accuracy: 0.8186274509803921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       962\n",
            "           1       0.65      0.33      0.44       262\n",
            "\n",
            "    accuracy                           0.82      1224\n",
            "   macro avg       0.75      0.64      0.66      1224\n",
            "weighted avg       0.80      0.82      0.79      1224\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning for Linear SVM"
      ],
      "metadata": {
        "id": "asLt2j2i5v9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", LinearSVC())\n",
        "])\n",
        "\n",
        "param_grid_svm = {\n",
        "    \"tfidf__max_features\": [3000, 5000, 8000],\n",
        "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
        "    \"clf__C\": [0.1, 1, 5]\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(\n",
        "    svm_pipeline,\n",
        "    param_grid=param_grid_svm,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best SVM params:\", grid_svm.best_params_)\n",
        "print(\"Best SVM CV score:\", grid_svm.best_score_)\n",
        "\n",
        "best_svm_model = grid_svm.best_estimator_\n",
        "\n",
        "y_pred_svm_best = best_svm_model.predict(X_test)\n",
        "print(\"Tuned SVM Test Accuracy:\", accuracy_score(y_test, y_pred_svm_best))\n",
        "print(classification_report(y_test, y_pred_svm_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGnX7ZUdt7SK",
        "outputId": "e3deda5f-08e3-4980-96db-fa5e0988b34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "Best SVM params: {'clf__C': 1, 'tfidf__max_features': 8000, 'tfidf__ngram_range': (1, 2)}\n",
            "Best SVM CV score: 0.8202247191011235\n",
            "Tuned SVM Test Accuracy: 0.8186274509803921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89       962\n",
            "           1       0.61      0.41      0.49       262\n",
            "\n",
            "    accuracy                           0.82      1224\n",
            "   macro avg       0.73      0.67      0.69      1224\n",
            "weighted avg       0.80      0.82      0.80      1224\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the Best Model for Prediction"
      ],
      "metadata": {
        "id": "Uf649Ja16KEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_genre_label(text, model=best_svm_model):\n",
        "    clean = clean_text(text)\n",
        "    pred = model.predict([clean])[0]\n",
        "    return pred, (\"Fiction\" if pred == 1 else \"Not Fiction\")\n",
        "\n",
        "sample_text = \"A magical story of a young boy who discovers a hidden world of wizards.\"\n",
        "# sample_text= \"A young detective follows mysterious clues that lead to a shocking secret.\"\n",
        "label_num, label_name = predict_genre_label(sample_text)\n",
        "\n",
        "print(\"Predicted label:\", label_num, \"=>\", label_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gprVptL0vHDJ",
        "outputId": "652cd540-8938-48c7-d8f5-0352753d30c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 1 => Fiction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0K4eLQyZvlkN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}